
## :book: CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection (NeurIPS2023)
<p align="center">
  <small>:fire: If CoDA is helpful for your community, please help to :star: it and share it. Thanks:fire:</small>
</p>

> [[Paper](https://arxiv.org/abs/2310.02960)] &emsp; [[Project Page](https://yangcaoai.github.io/publications/CoDA.html)] <br>
<!-- > [Yang Cao](https://harlanhong.github.io), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br> -->
<!-- > The Hong Kong University of Science and Technology, Huawei Noah's Ark Lab -->
> [Yang Cao](https://harlanhong.github.io), Yihan Zeng, [Hang Xu](https://xuhangcn.github.io/), [Dan Xu](https://www.danxurgb.net) <br>
> The Hong Kong University of Science and Technology<br>
> Huawei Noah's Ark Lab

## Samples  
<img src="assets/CoDA_sup_fig0_v3_cropped.png">
<img src="assets/CoDA_sup_fig1_v3_cropped.png">

## Framework  
<img src="assets/ov3d_det.png">


:triangular_flag_on_post: **Updates**  
All the data, codes and pretrain models will be released soon.

## :scroll: BibTeX
If CoDA is helpful, please cite:
```
@misc{cao2023coda,
      title={CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection}, 
      author={Yang Cao and Yihan Zeng and Hang Xu and Dan Xu},
      year={2023},
      eprint={2310.02960},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}          
```

### :e-mail: Contact

If you have any question or collaboration need (research purpose or commercial purpose), please email `yangcao.cs@gmail.com`.

## :scroll: Acknowledgement
CoDA is inspired by [CLIP](https://github.com/openai/CLIP) and [3DETR](https://github.com/facebookresearch/3detr). We appreciate their great codes.
